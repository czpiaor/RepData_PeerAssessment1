}
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
y
library(datasets)
data(iris)
source("C:/Users/aliu/Documents/Data Science Coursera/R Programming/Week 3/cachematrix.R")
my_matrix <- makeCacheMatrix(matrix(1:4, 2, 2))
my_matrix$get()
my_matrix$getInverse()
cacheSolve(my_matrix)
my_matrix$getInverse()
my_matrix$set(matrix(c(2, 2, 1, 4), 2, 2))
my_matrix$get()
cacheSolve(my_matrix)
my_matrix$getInverse()
source("C:/Users/aliu/ProgrammingAssignment2/cachematrix.R")
my_matrix$set(matrix(c(2, 2, 1, 4), 2, 2))
my_matrix$get()
cacheSolve(my_matrix)
my_matrix$getInverse()
source("C:/Users/aliu/ProgrammingAssignment2/cachematrix.R")
my_matrix$set(matrix(c(2, 2, 1, 4), 2, 2))
my_matrix$get()
cacheSolve(my_matrix)
my_matrix$getInverse()
swirl()
library(swirl)
swirl()
1:20
pi:10
15:1
?:
?':'
seq(1,20)
seq(0,10,by=0.5)
my_seq<-seq(5,10,length=30)
length(my_seq)
1:length(my_seq)
seq(long.with=my_seq)
seq(along.with=my_seq)
seq_along(my_seq)
rep(0,times=40)
rep(c(0,1,2),times=10)
rep(c(0,1,2),each=10)
num_vect<-c(0.5,55,-10,6)
tf<- num_vect<1
tf
num_vect>=6
my_char <- c("My", "name", "is")
my_char
paste(my_char, collapse = " ")
my_name <-  c(my_char, "Alex")
my_name
paste(my_char, collapse = " ")
paste(my_name, collapse = " ")
paste("Hello", "world!", sep = " ")
paste(1:3,c("X", "Y", "Z"),collapse = "")
paste(1:3,c("X", "Y", "Z"),sep = "")
paste(LETTERS, 1:4, sep = "-")
x<-c(44, NA, 5, NA)
x*3
y <- rnorm(1000)
z <- rep(NA, 1000)
my_data <- sample(c(y, z), 100)
my_na<-is.na(my_data)
my_na
my_data ==NA
sum(my_na)
my_data
0/0
inf-inf
Inf-Inf
packageVersion("swirl")
library(swirl)
install_from_swirl("Exploratory Data Analysis")
install_from_swirl("Exploratory Data Analysis")
swirl()
install.packages("ggplot2")
library(swirl)
swirl()
q()
## ------------------------------------------------------------------------
# plot the histogram of averages
hist(row_means, breaks=50, prob=TRUE,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
# density of the averages of samples
lines(density(row_means))
set.seed(Alex)
set.seed(31)
lambda <- 0.2
num_sim <- 1000
sample_size <- 40
sim <- matrix(rexp(num_sim*sample_size, rate=lambda), num_sim, sample_size)
row_means <- rowMeans(sim)
## ------------------------------------------------------------------------
# plot the histogram of averages
hist(row_means, breaks=50, prob=TRUE,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
# density of the averages of samples
lines(density(row_means))
# theoretical center of distribution
abline(v=1/lambda, col="red")
# theoretical density of the averages of samples
xfit <- seq(min(row_means), max(row_means), length=100)
yfit <- dnorm(xfit, mean=1/lambda, sd=(1/lambda/sqrt(sample_size)))
lines(xfit, yfit, pch=22, col="red", lty=2)
# add legend
legend('topright', c("simulation", "theoretical"), lty=c(1,2), col=c("black", "red"))
## ------------------------------------------------------------------------
qqnorm(row_means); qqline(row_means)
## ------------------------------------------------------------------------
lambda_vals <- seq(4, 6, by=0.01)
coverage <- sapply(lambda_vals, function(lamb) {
mu_hats <- rowMeans(matrix(rexp(sample_size*num_sim, rate=0.2),
num_sim, sample_size))
ll <- mu_hats - qnorm(0.975) * sqrt(1/lambda**2/sample_size)
ul <- mu_hats + qnorm(0.975) * sqrt(1/lambda**2/sample_size)
mean(ll < lamb & ul > lamb)
})
library(ggplot2)
qplot(lambda_vals, coverage) + geom_hline(yintercept=0.95)
hist(row_means, breaks=50, prob=TRUE,color = blues9,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
hist(row_means, breaks=50, prob=TRUE,col = blues9,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
# density of the averages of samples
lines(density(row_means))
# theoretical center of distribution
abline(v=1/lambda, col="red")
# theoretical density of the averages of samples
xfit <- seq(min(row_means), max(row_means), length=100)
yfit <- dnorm(xfit, mean=1/lambda, sd=(1/lambda/sqrt(sample_size)))
lines(xfit, yfit, pch=22, col="red", lty=2)
# add legend
legend('topright', c("simulation", "theoretical"), lty=c(1,2), col=c("black", "red"))
## ------------------------------------------------------------------------
install.packages("knitr")
install.packages("pdflatex")
install.packages("latex")
sudo apt-get install texlive-latex-extra
echo $PATH
install.packages("rmarkdown")
install.packages("rmarkdown")
Sys.getenv("PATH")
$ brew update
$ brew install pandoc
brew update
install.packages("C:/Users/aliu/Downloads/basictex-20150613.pkg", repos = NULL)
install.packages("C:/Users/aliu/Downloads/basictex-20150613.pkg")
install.packages("C:/Users/aliu/Downloads/basictex-20150613.pkg", repos = NULL)
pandoc_available
devtools::install_github("rstudio/rmarkdown")
install_github("rstudio/rmarkdown")
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
set.seed(31)
lambda <- 0.2
num_sim <- 1000
sample_size <- 40
sim <- matrix(rexp(num_sim*sample_size, rate=lambda), num_sim, sample_size)
row_means <- rowMeans(sim)
row_mwans
row_means
meanofMeans <- mean(row_means)
meanofMeans
library(datasets) #This library provides free databases
data(mtcars) #The database I will use
summary(mtcars) #mean, median and quatiles
var(mtcars) #variance-covariance matrix
analysis <- aov(mpg ~ ., data = mtcars) #I run ANOVA
summary(analysis) #this returns a summary containing relevant statistics
lm <- lm(mpg ~ cyl + wt + am + disp + hp + qsec + carb + gear, data = mtcars)
summary(lm)
mtcars$vs <- as.factor(mtcars$vs)
mtcars$am <- as.factor(mtcars$am)
??mfrow
?mfrow
boxplot(mpg ~ am, data = mtcars, xlab = "AM (Transmission type)",
ylab = "MPG (Miles per galon)", main="Boxplot", xaxt="n", col=c("red","blue"))
axis(1, at=c(1,2), labels=c("automatic", "manual"))
##par(mar=c(2.5, 5.5, 1.5, 1.5))
plot(lm)
library(datasets) #This library provides free databases
data(mtcars) #The database I will use
summary(mtcars) #mean, median and quatiles
var(mtcars) #variance-covariance matrix
analysis <- aov(mpg ~ ., data = mtcars) #I run ANOVA
summary(analysis) #this returns a summary containing relevant statistics
lm <- lm(mpg ~ cyl  + am + disp + hp + qsec + carb + gear, data = mtcars)
summary(lm)
mtcars$vs <- as.factor(mtcars$vs)
mtcars$am <- as.factor(mtcars$am)
par(mfrow=c(3,2))
par(mar=c(2.5, 5.5, 1.5, 1.5))
boxplot(mpg ~ am, data = mtcars, xlab = "AM (Transmission type)",
ylab = "MPG (Miles per galon)", main="Boxplot", xaxt="n", col=c("red","blue"))
axis(1, at=c(1,2), labels=c("automatic", "manual"))
par(mar=c(2.5, 5.5, 1.5, 1.5))
plot(lm)
library(datasets) #This library provides free databases
data(mtcars) #The database I will use
summary(mtcars) #mean, median and quatiles
var(mtcars) #variance-covariance matrix
analysis <- aov(mpg ~ ., data = mtcars) #I run ANOVA
summary(analysis) #this returns a summary containing relevant statistics
lm <- lm(mpg ~ am , data = mtcars)
summary(lm)
summary(lm(mpg ~ . , data = mtcars))
lm <- lm(mpg ~ am , data = mtcars)
summary(lm)
anova(lm)
lm0<-lm(mpg ~ . , data = mtcars)
summary(lm0)
anova(lm0)
predict(lm0,interval ="confidence")
mtcars
help (resid)
lm1<-lm(mpg ~ disp + drat + WT + qsec + am + vs + gear , data = mtcars)
lm1<-lm(mpg ~ disp + drat + wt + qsec + am + vs + gear , data = mtcars)
summary(lm1)
lm1<-lm(mpg ~ disp + drat + wt + qsec + am + vs + gear +carb , data = mtcars)
summary(lm1)
anova(lm1)
predict(lm1,interval ="confidence")
lm1<-lm(mpg ~ disp + drat + wt + qsec + am + vs + gear +carb + hp , data = mtcars)
summary(lm1)
lm1<-lm(mpg ~ disp + drat + wt + qsec + am + vs + gear +carb + hp +syl , data = mtcars)
lm1<-lm(mpg ~ disp + drat + wt + qsec + am + vs + gear +carb + hp +cyl , data = mtcars)
summary(lm1)
lm1<-lm(mpg ~ disp + drat + wt + qsec + am + vs + gear +carb + hp , data = mtcars)
summary(lm1)
lm1<-lm(mpg ~ disp + drat + wt + qsec + am + vs + gear +carb  , data = mtcars)
summary(lm1)
library(GGally)
library(ggplot2)
install.packages("GGally")
library(GGally)
library(ggplot2)
ggpairs(mtcars,
lower = list(continuous = "smooth",params = c(method = "loess", colour="blue")),
diag=list(continuous="bar", params=c(colour="blue")),
upper=list(params=list(corSize=15)),
axisLabels='show')
library(knitr)
library(printr)
install.packages("printr")
library(knitr)
library(printr)
kable(head(mtcars),align = 'c')
library(GGally)
library(ggplot2)
ggpairs(mtcars,
lower = list(continuous = "smooth",params = c(method = "loess", colour="blue")),
diag=list(continuous="bar", params=c(colour="blue")),
upper=list(params=list(corSize=15)),
axisLabels='show')
ggpairs(mtcars,
lower = list(continuous = "smooth",params = c(method = "loess", colour="blue")),
diag=list(continuous="bar", params=c(colour="blue")),
upper=list(corSize=15),
axisLabels='show')
library(datasets) #This library provides free databases
data(mtcars) #The database I will use
summary(mtcars) #mean, median and quatiles
var(mtcars) #variance-covariance matrix
kable(head(mtcars),align = 'c')
summary(lm(mpg ~ cyl+disp+hp+drat+wt+qsec+factor(vs)+factor(am)+gear+carb, data = mtcars))$coef
summary(lm)
summary(lm(mpg ~ cyl+disp+hp+drat+wt+qsec+factor(vs)+factor(am)+gear+carb, data = mtcars))
lm <- lm(mpg ~ am , data = mtcars)
summary(lm)
lm0<-lm(mpg ~ . , data = mtcars)
summary(lm0)
anova(lm0)
anova(lm1)
lm0<-lm(mpg ~ . , data = mtcars)
summary(lm0)
anova(lm0)
anova(lm0,lm1)
lm2<-lm(mpg ~ disp + drat + wt + qsec + am  , data = mtcars)
summary(lm2)
anova(lm0,lm1,lm2)
lm3<-lm(mpg ~ am+wt+qsec+hp+drat  , data = mtcars)
summary(lm3)
anova(lm0,lm1,lm2,lm3)
lm0<-lm(mpg ~ am , data = mtcars)
summary(lm0)
anova(lm0)
predict(lm0,interval ="confidence")
lm1<-lm(mpg ~ am+wt  , data = mtcars)
summary(lm1)
lm2<-lm(mpg ~ am+wt+qsec   , data = mtcars)
summary(lm2)
lm3<-lm(mpg ~ am+wt+qsec+hp  , data = mtcars)
summary(lm3)
lm4<-lm(mpg ~ am+wt+qsec+hp+drat  , data = mtcars)
summary(lm3)
anova(lm0,lm1,lm2,lm3,lm4)
lm5<-lm(mpg ~ am+wt+qsec+hp+drat+vs+gear+carb  , data = mtcars)
summary(lm5)
anova(lm0,lm1,lm2,lm3,lm4,lm5)
lm5<-lm(mpg ~ am+wt+qsec+hp+drat+vs+cyl+disp , data = mtcars)
summary(lm5)
anova(lm0,lm1,lm2,lm3,lm4,lm5)
lm5<-lm(mpg ~ am+wt+qsec+hp+drat+vs+cyl, data = mtcars)
summary(lm5)
anova(lm0,lm1,lm2,lm3,lm4,lm5)
lm6<-lm(mpg ~ am+wt+qsec+hp+drat+vs+cyl+disp, data = mtcars)
summary(lm6)
anova(lm0,lm1,lm2,lm3,lm4,lm5,lm6)
summary(lm5)
library(datasets) #This library provides free databases
data(mtcars) #The database I will use
summary(mtcars) #mean, median and quatiles
var(mtcars) #variance-covariance matrix
library(knitr)
kable(head(mtcars),align = 'c')
analysis <- aov(mpg ~ ., data = mtcars) #I run ANOVA
summary(analysis) #this returns a summary containing relevant statistics
lm0<-lm(mpg ~ am , data = mtcars)
summary(lm0)
anova(lm0)
predict(lm0,interval ="confidence")
lm1<-lm(mpg ~ am+wt  , data = mtcars)
summary(lm1)
lm2<-lm(mpg ~ am+wt+qsec   , data = mtcars)
summary(lm2)
lm3<-lm(mpg ~ am+wt+qsec+hp  , data = mtcars)
summary(lm3)
lm4<-lm(mpg ~ am+wt+qsec+hp+drat  , data = mtcars)
summary(lm4)
lm5<-lm(mpg ~ am+wt+qsec+hp+drat+vs+cyl, data = mtcars)
summary(lm5)
lm6<-lm(mpg ~ am+wt+qsec+hp+drat+vs+cyl+disp, data = mtcars)
summary(lm6)
anova(lm0,lm1,lm2,lm3,lm4,lm5,lm6)
predict(lm1,interval ="confidence")
summary(lm)
anova(lm)
mtcars$vs <- as.factor(mtcars$vs)
mtcars$am <- as.factor(mtcars$am)
par(mfrow=c(3,2))
par(mar=c(2.5, 5.5, 1.5, 1.5))
boxplot(mpg ~ am, data = mtcars, xlab = "AM (Transmission type)",
ylab = "MPG (Miles per galon)", main="Boxplot", xaxt="n", col=c("red","blue"))
axis(1, at=c(1,2), labels=c("automatic", "manual"))
par(mar=c(2.5, 5.5, 1.5, 1.5))
analysis <- aov(mpg ~ ., data = mtcars) #I run ANOVA
summary(analysis) #this returns a summary containing relevant statistics
plot(lm5)
summary(lm5)
setwd("/Users/aliu/Documents/Data_Science_Coursera/RepData_PeerAssessment1")
## ----loaddata------------------------------------------------------------
unzip(zipfile="activity.zip")
data <- read.csv("activity.csv")
## ------------------------------------------------------------------------
library(ggplot2)
total.steps <- tapply(data$steps, data$date, FUN=sum, na.rm=TRUE)
qplot(total.steps, binwidth=1000, xlab="total number of steps taken each day")
mean(total.steps, na.rm=TRUE)
median(total.steps, na.rm=TRUE)
## ------------------------------------------------------------------------
##library(ggplot2)
averages <- aggregate(x=list(steps=data$steps), by=list(interval=data$interval),
FUN=mean, na.rm=TRUE)
ggplot(data=averages, aes(x=interval, y=steps)) +
geom_line() +
xlab("5-minute interval") +
ylab("average number of steps taken")
## ------------------------------------------------------------------------
averages[which.max(averages$steps),]
## ----how_many_missing----------------------------------------------------
missing <- is.na(data$steps)
# How many missing
table(missing)
## ------------------------------------------------------------------------
# Replace each missing value with the mean value of its 5-minute interval
fill.value <- function(steps, interval) {
filled <- NA
getwd()
setwd("/Users/aliu/Documents/Data_Science_Coursera/RepData_PeerAssessment1")
## ----loaddata------------------------------------------------------------
if(!file.exists('activity.csv')){
unzip('activity.zip')
}
data <- read.csv("activity.csv")
## ------------------------------------------------------------------------
library(ggplot2)
total.steps <- tapply(data$steps, data$date, FUN=sum, na.rm=TRUE)
qplot(total.steps, binwidth=1000, xlab="total number of steps taken each day")
mean(total.steps, na.rm=TRUE)
median(total.steps, na.rm=TRUE)
## ------------------------------------------------------------------------
##library(ggplot2)
averages <- aggregate(x=list(steps=data$steps), by=list(interval=data$interval),
FUN=mean, na.rm=TRUE)
ggplot(data=averages, aes(x=interval, y=steps)) +
ggplot(data=averages, aes(x=interval, y=steps)) +
source('~/Data_Science_Coursera/RepData_PeerAssessment1/PA1.R', echo=TRUE)
## ----loaddata------------------------------------------------------------
if(!file.exists('activity.csv')){
unzip('activity.zip')
}
data <- read.csv("activity.csv")
## ------------------------------------------------------------------------
if (!is.na(steps))
filled <- c(steps)
else
filled <- (averages[averages$interval==interval, "steps"])
return(filled)
}
filled.data <- data
filled.data$steps <- mapply(fill.value, filled.data$steps, filled.data$interval)
getwd()
setwd("/Users/aliu/Documents/Data_Science_Coursera/RepData_PeerAssessment1")
## ----loaddata------------------------------------------------------------
if(!file.exists('activity.csv')){
unzip('activity.zip')
}
data <- read.csv("activity.csv")
## ------------------------------------------------------------------------
library(ggplot2)
total.steps <- tapply(data$steps, data$date, FUN=sum, na.rm=TRUE)
qplot(total.steps, binwidth=1000, xlab="total number of steps taken each day")
mean(total.steps, na.rm=TRUE)
median(total.steps, na.rm=TRUE)
## ------------------------------------------------------------------------
##library(ggplot2)
averages <- aggregate(x=list(steps=data$steps), by=list(interval=data$interval),
FUN=mean, na.rm=TRUE)
ggplot(data=averages, aes(x=interval, y=steps)) +
geom_line() +
xlab("5-minute interval") +
ylab("average number of steps taken")
## ------------------------------------------------------------------------
averages[which.max(averages$steps),]
## ----how_many_missing----------------------------------------------------
missing <- is.na(data$steps)
# How many missing
table(missing)
## ------------------------------------------------------------------------
# Replace each missing value with the mean value of its 5-minute interval
fill.value <- function(steps, interval) {
filled <- NA
if (!is.na(steps))
filled <- c(steps)
else
filled <- (averages[averages$interval==interval, "steps"])
return(filled)
}
filled.data <- data
filled.data$steps <- mapply(fill.value, filled.data$steps, filled.data$interval)
## ------------------------------------------------------------------------
total.steps <- tapply(filled.data$steps, filled.data$date, FUN=sum)
qplot(total.steps, binwidth=1000, xlab="total number of steps taken each day")
mean(total.steps)
median(total.steps)
## ------------------------------------------------------------------------
weekday.or.weekend <- function(date) {
day <- weekdays(date)
if (day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday"))
return("weekday")
else if (day %in% c("Saturday", "Sunday"))
return("weekend")
else
stop("invalid date")
}
filled.data$date <- as.Date(filled.data$date)
filled.data$day <- sapply(filled.data$date, FUN=weekday.or.weekend)
## ------------------------------------------------------------------------
averages <- aggregate(steps ~ interval + day, data=filled.data, mean)
ggplot(averages, aes(interval, steps)) + geom_line() + facet_grid(day ~ .) +
xlab("5-minute interval") + ylab("Number of steps")
total.steps <- tapply(data$steps, data$date, FUN=sum, na.rm=TRUE)
qplot(total.steps, binwidth=1000, xlab="total number of steps taken each day")
mean(total.steps, na.rm=TRUE)
median(total.steps, na.rm=TRUE)
data$date
total.steps <- tapply(data$steps, data$date, FUN=sum, na.rm=TRUE)
qplot(total.steps, binwidth=1000, xlab="total number of steps taken each day")
mean(total.steps, na.rm=TRUE)
median(total.steps, na.rm=TRUE)
## ------------------------------------------------------------------------
##library(ggplot2)
averages <- aggregate(x=list(steps=data$steps), by=list(interval=data$interval),
FUN=mean, na.rm=TRUE)
ggplot(data=averages, aes(x=interval, y=steps)) +
geom_line() +
xlab("5-minute interval") +
ylab("average number of steps taken")
## ------------------------------------------------------------------------
