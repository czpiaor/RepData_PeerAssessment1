#elements of a vector all must be of the same class
#elements of a vector can only be character or numeric
#Question 8
#Suppose I have a list defined as x <- list(2, "a", "b", TRUE). What does x[[2]] give me?
x <- list(2, "a", "b", TRUE)
x[[2]]
#Question 9
#Suppose I have a vector x <- 1:4 and a vector y <- 2. What is produced by the expression x + y?
x <- 1:4
y <- 2
x + y
#Question 10
#Suppose I have a vector x <- c(17, 14, 4, 5, 13, 12, 10) and I want to set all elements of this vector that are greater than 10 to be equal to 4. What R code achieves this?
x <- c(17, 14, 4, 5, 13, 12, 10)
x[x >= 11] <- 4
#Question 11
#In the dataset provided for this Quiz, what are the column names of the dataset?
names(mydata)
#Question 12
#Extract the first 2 rows of the data frame and print them to the console. What does the output look like?
mydata[c(1,2),]
#Question 13
#How many observations (i.e. rows) are in this data frame?
nrow(mydata)
#Question 14
#Extract the last 2 rows of the data frame and print them to the console. What does the output look like?
mydata[c(152,153),]
#Question 15
#What is the value of Ozone in the 47th row?
mydata[47,]
#Question 16
#How many missing values are in the Ozone column of this data frame?
#para 1 variable
sum(is.na(mydata$Ozone))
#para toda la matriz
propmiss <- function(dataframe) lapply(dataframe,function(x) data.frame(nmiss=sum(is.na(x)), n=length(x), propmiss=sum(is.na(x))/length(x)))
propmiss(mydata)
#Question 17
#What is the mean of the Ozone column in this dataset? Exclude missing values (coded as NA) from this calculation.
#forma 1
mean(mydata$Ozone,na.rm=TRUE)
#forma 2
sum(mydata$Ozone,na.rm=TRUE)/sum(!is.na(mydata$Ozone))
#Question 18
#Extract the subset of rows of the data frame where Ozone values are above 31 and Temp values are above 90. What is the mean of Solar.R in this subset?
mean(mydata$Solar.R [mydata$Ozone>31 & mydata$Temp>90], na.rm=TRUE)
#Question 19
#What is the mean of "Temp" when "Month" is equal to 6?
mean(mydata$Temp [mydata$Month==6], na.rm=TRUE)
#Question 20
#What was the maximum ozone value in the month of May (i.e. Month = 5)?
max(mydata$Ozone [mydata$Month==5], na.rm=TRUE)
x <- 1:10
if(x > 5) {
x <- 0
}
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
y
library(datasets)
data(iris)
source("C:/Users/aliu/Documents/Data Science Coursera/R Programming/Week 3/cachematrix.R")
my_matrix <- makeCacheMatrix(matrix(1:4, 2, 2))
my_matrix$get()
my_matrix$getInverse()
cacheSolve(my_matrix)
my_matrix$getInverse()
my_matrix$set(matrix(c(2, 2, 1, 4), 2, 2))
my_matrix$get()
cacheSolve(my_matrix)
my_matrix$getInverse()
source("C:/Users/aliu/ProgrammingAssignment2/cachematrix.R")
my_matrix$set(matrix(c(2, 2, 1, 4), 2, 2))
my_matrix$get()
cacheSolve(my_matrix)
my_matrix$getInverse()
source("C:/Users/aliu/ProgrammingAssignment2/cachematrix.R")
my_matrix$set(matrix(c(2, 2, 1, 4), 2, 2))
my_matrix$get()
cacheSolve(my_matrix)
my_matrix$getInverse()
swirl()
library(swirl)
swirl()
1:20
pi:10
15:1
?:
?':'
seq(1,20)
seq(0,10,by=0.5)
my_seq<-seq(5,10,length=30)
length(my_seq)
1:length(my_seq)
seq(long.with=my_seq)
seq(along.with=my_seq)
seq_along(my_seq)
rep(0,times=40)
rep(c(0,1,2),times=10)
rep(c(0,1,2),each=10)
num_vect<-c(0.5,55,-10,6)
tf<- num_vect<1
tf
num_vect>=6
my_char <- c("My", "name", "is")
my_char
paste(my_char, collapse = " ")
my_name <-  c(my_char, "Alex")
my_name
paste(my_char, collapse = " ")
paste(my_name, collapse = " ")
paste("Hello", "world!", sep = " ")
paste(1:3,c("X", "Y", "Z"),collapse = "")
paste(1:3,c("X", "Y", "Z"),sep = "")
paste(LETTERS, 1:4, sep = "-")
x<-c(44, NA, 5, NA)
x*3
y <- rnorm(1000)
z <- rep(NA, 1000)
my_data <- sample(c(y, z), 100)
my_na<-is.na(my_data)
my_na
my_data ==NA
sum(my_na)
my_data
0/0
inf-inf
Inf-Inf
packageVersion("swirl")
library(swirl)
install_from_swirl("Exploratory Data Analysis")
install_from_swirl("Exploratory Data Analysis")
swirl()
install.packages("ggplot2")
library(swirl)
swirl()
q()
## ------------------------------------------------------------------------
# plot the histogram of averages
hist(row_means, breaks=50, prob=TRUE,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
# density of the averages of samples
lines(density(row_means))
set.seed(Alex)
set.seed(31)
lambda <- 0.2
num_sim <- 1000
sample_size <- 40
sim <- matrix(rexp(num_sim*sample_size, rate=lambda), num_sim, sample_size)
row_means <- rowMeans(sim)
## ------------------------------------------------------------------------
# plot the histogram of averages
hist(row_means, breaks=50, prob=TRUE,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
# density of the averages of samples
lines(density(row_means))
# theoretical center of distribution
abline(v=1/lambda, col="red")
# theoretical density of the averages of samples
xfit <- seq(min(row_means), max(row_means), length=100)
yfit <- dnorm(xfit, mean=1/lambda, sd=(1/lambda/sqrt(sample_size)))
lines(xfit, yfit, pch=22, col="red", lty=2)
# add legend
legend('topright', c("simulation", "theoretical"), lty=c(1,2), col=c("black", "red"))
## ------------------------------------------------------------------------
qqnorm(row_means); qqline(row_means)
## ------------------------------------------------------------------------
lambda_vals <- seq(4, 6, by=0.01)
coverage <- sapply(lambda_vals, function(lamb) {
mu_hats <- rowMeans(matrix(rexp(sample_size*num_sim, rate=0.2),
num_sim, sample_size))
ll <- mu_hats - qnorm(0.975) * sqrt(1/lambda**2/sample_size)
ul <- mu_hats + qnorm(0.975) * sqrt(1/lambda**2/sample_size)
mean(ll < lamb & ul > lamb)
})
library(ggplot2)
qplot(lambda_vals, coverage) + geom_hline(yintercept=0.95)
hist(row_means, breaks=50, prob=TRUE,color = blues9,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
hist(row_means, breaks=50, prob=TRUE,col = blues9,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
# density of the averages of samples
lines(density(row_means))
# theoretical center of distribution
abline(v=1/lambda, col="red")
# theoretical density of the averages of samples
xfit <- seq(min(row_means), max(row_means), length=100)
yfit <- dnorm(xfit, mean=1/lambda, sd=(1/lambda/sqrt(sample_size)))
lines(xfit, yfit, pch=22, col="red", lty=2)
# add legend
legend('topright', c("simulation", "theoretical"), lty=c(1,2), col=c("black", "red"))
## ------------------------------------------------------------------------
install.packages("knitr")
install.packages("pdflatex")
install.packages("latex")
sudo apt-get install texlive-latex-extra
echo $PATH
install.packages("rmarkdown")
install.packages("rmarkdown")
Sys.getenv("PATH")
$ brew update
$ brew install pandoc
brew update
install.packages("C:/Users/aliu/Downloads/basictex-20150613.pkg", repos = NULL)
install.packages("C:/Users/aliu/Downloads/basictex-20150613.pkg")
install.packages("C:/Users/aliu/Downloads/basictex-20150613.pkg", repos = NULL)
pandoc_available
devtools::install_github("rstudio/rmarkdown")
install_github("rstudio/rmarkdown")
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
set.seed(31)
lambda <- 0.2
num_sim <- 1000
sample_size <- 40
sim <- matrix(rexp(num_sim*sample_size, rate=lambda), num_sim, sample_size)
row_means <- rowMeans(sim)
row_mwans
row_means
meanofMeans <- mean(row_means)
meanofMeans
library(datasets) #This library provides free databases
data(mtcars) #The database I will use
summary(mtcars) #mean, median and quatiles
var(mtcars) #variance-covariance matrix
analysis <- aov(mpg ~ ., data = mtcars) #I run ANOVA
summary(analysis) #this returns a summary containing relevant statistics
lm <- lm(mpg ~ cyl + wt + am + disp + hp + qsec + carb + gear, data = mtcars)
summary(lm)
mtcars$vs <- as.factor(mtcars$vs)
mtcars$am <- as.factor(mtcars$am)
??mfrow
?mfrow
boxplot(mpg ~ am, data = mtcars, xlab = "AM (Transmission type)",
ylab = "MPG (Miles per galon)", main="Boxplot", xaxt="n", col=c("red","blue"))
axis(1, at=c(1,2), labels=c("automatic", "manual"))
##par(mar=c(2.5, 5.5, 1.5, 1.5))
plot(lm)
library(datasets) #This library provides free databases
data(mtcars) #The database I will use
summary(mtcars) #mean, median and quatiles
var(mtcars) #variance-covariance matrix
analysis <- aov(mpg ~ ., data = mtcars) #I run ANOVA
summary(analysis) #this returns a summary containing relevant statistics
lm <- lm(mpg ~ cyl  + am + disp + hp + qsec + carb + gear, data = mtcars)
summary(lm)
mtcars$vs <- as.factor(mtcars$vs)
mtcars$am <- as.factor(mtcars$am)
par(mfrow=c(3,2))
par(mar=c(2.5, 5.5, 1.5, 1.5))
boxplot(mpg ~ am, data = mtcars, xlab = "AM (Transmission type)",
ylab = "MPG (Miles per galon)", main="Boxplot", xaxt="n", col=c("red","blue"))
axis(1, at=c(1,2), labels=c("automatic", "manual"))
par(mar=c(2.5, 5.5, 1.5, 1.5))
plot(lm)
library(datasets) #This library provides free databases
data(mtcars) #The database I will use
summary(mtcars) #mean, median and quatiles
var(mtcars) #variance-covariance matrix
analysis <- aov(mpg ~ ., data = mtcars) #I run ANOVA
summary(analysis) #this returns a summary containing relevant statistics
lm <- lm(mpg ~ am , data = mtcars)
summary(lm)
summary(lm(mpg ~ . , data = mtcars))
lm <- lm(mpg ~ am , data = mtcars)
summary(lm)
anova(lm)
lm0<-lm(mpg ~ . , data = mtcars)
summary(lm0)
anova(lm0)
predict(lm0,interval ="confidence")
mtcars
help (resid)
lm1<-lm(mpg ~ disp + drat + WT + qsec + am + vs + gear , data = mtcars)
lm1<-lm(mpg ~ disp + drat + wt + qsec + am + vs + gear , data = mtcars)
summary(lm1)
lm1<-lm(mpg ~ disp + drat + wt + qsec + am + vs + gear +carb , data = mtcars)
summary(lm1)
anova(lm1)
predict(lm1,interval ="confidence")
lm1<-lm(mpg ~ disp + drat + wt + qsec + am + vs + gear +carb + hp , data = mtcars)
summary(lm1)
lm1<-lm(mpg ~ disp + drat + wt + qsec + am + vs + gear +carb + hp +syl , data = mtcars)
lm1<-lm(mpg ~ disp + drat + wt + qsec + am + vs + gear +carb + hp +cyl , data = mtcars)
summary(lm1)
lm1<-lm(mpg ~ disp + drat + wt + qsec + am + vs + gear +carb + hp , data = mtcars)
summary(lm1)
lm1<-lm(mpg ~ disp + drat + wt + qsec + am + vs + gear +carb  , data = mtcars)
summary(lm1)
library(GGally)
library(ggplot2)
install.packages("GGally")
library(GGally)
library(ggplot2)
ggpairs(mtcars,
lower = list(continuous = "smooth",params = c(method = "loess", colour="blue")),
diag=list(continuous="bar", params=c(colour="blue")),
upper=list(params=list(corSize=15)),
axisLabels='show')
library(knitr)
library(printr)
install.packages("printr")
library(knitr)
library(printr)
kable(head(mtcars),align = 'c')
library(GGally)
library(ggplot2)
ggpairs(mtcars,
lower = list(continuous = "smooth",params = c(method = "loess", colour="blue")),
diag=list(continuous="bar", params=c(colour="blue")),
upper=list(params=list(corSize=15)),
axisLabels='show')
ggpairs(mtcars,
lower = list(continuous = "smooth",params = c(method = "loess", colour="blue")),
diag=list(continuous="bar", params=c(colour="blue")),
upper=list(corSize=15),
axisLabels='show')
library(datasets) #This library provides free databases
data(mtcars) #The database I will use
summary(mtcars) #mean, median and quatiles
var(mtcars) #variance-covariance matrix
kable(head(mtcars),align = 'c')
summary(lm(mpg ~ cyl+disp+hp+drat+wt+qsec+factor(vs)+factor(am)+gear+carb, data = mtcars))$coef
summary(lm)
summary(lm(mpg ~ cyl+disp+hp+drat+wt+qsec+factor(vs)+factor(am)+gear+carb, data = mtcars))
lm <- lm(mpg ~ am , data = mtcars)
summary(lm)
lm0<-lm(mpg ~ . , data = mtcars)
summary(lm0)
anova(lm0)
anova(lm1)
lm0<-lm(mpg ~ . , data = mtcars)
summary(lm0)
anova(lm0)
anova(lm0,lm1)
lm2<-lm(mpg ~ disp + drat + wt + qsec + am  , data = mtcars)
summary(lm2)
anova(lm0,lm1,lm2)
lm3<-lm(mpg ~ am+wt+qsec+hp+drat  , data = mtcars)
summary(lm3)
anova(lm0,lm1,lm2,lm3)
lm0<-lm(mpg ~ am , data = mtcars)
summary(lm0)
anova(lm0)
predict(lm0,interval ="confidence")
lm1<-lm(mpg ~ am+wt  , data = mtcars)
summary(lm1)
lm2<-lm(mpg ~ am+wt+qsec   , data = mtcars)
summary(lm2)
lm3<-lm(mpg ~ am+wt+qsec+hp  , data = mtcars)
summary(lm3)
lm4<-lm(mpg ~ am+wt+qsec+hp+drat  , data = mtcars)
summary(lm3)
anova(lm0,lm1,lm2,lm3,lm4)
lm5<-lm(mpg ~ am+wt+qsec+hp+drat+vs+gear+carb  , data = mtcars)
summary(lm5)
anova(lm0,lm1,lm2,lm3,lm4,lm5)
lm5<-lm(mpg ~ am+wt+qsec+hp+drat+vs+cyl+disp , data = mtcars)
summary(lm5)
anova(lm0,lm1,lm2,lm3,lm4,lm5)
lm5<-lm(mpg ~ am+wt+qsec+hp+drat+vs+cyl, data = mtcars)
summary(lm5)
anova(lm0,lm1,lm2,lm3,lm4,lm5)
lm6<-lm(mpg ~ am+wt+qsec+hp+drat+vs+cyl+disp, data = mtcars)
summary(lm6)
anova(lm0,lm1,lm2,lm3,lm4,lm5,lm6)
summary(lm5)
library(datasets) #This library provides free databases
data(mtcars) #The database I will use
summary(mtcars) #mean, median and quatiles
var(mtcars) #variance-covariance matrix
library(knitr)
kable(head(mtcars),align = 'c')
analysis <- aov(mpg ~ ., data = mtcars) #I run ANOVA
summary(analysis) #this returns a summary containing relevant statistics
lm0<-lm(mpg ~ am , data = mtcars)
summary(lm0)
anova(lm0)
predict(lm0,interval ="confidence")
lm1<-lm(mpg ~ am+wt  , data = mtcars)
summary(lm1)
lm2<-lm(mpg ~ am+wt+qsec   , data = mtcars)
summary(lm2)
lm3<-lm(mpg ~ am+wt+qsec+hp  , data = mtcars)
summary(lm3)
lm4<-lm(mpg ~ am+wt+qsec+hp+drat  , data = mtcars)
summary(lm4)
lm5<-lm(mpg ~ am+wt+qsec+hp+drat+vs+cyl, data = mtcars)
summary(lm5)
lm6<-lm(mpg ~ am+wt+qsec+hp+drat+vs+cyl+disp, data = mtcars)
summary(lm6)
anova(lm0,lm1,lm2,lm3,lm4,lm5,lm6)
predict(lm1,interval ="confidence")
summary(lm)
anova(lm)
mtcars$vs <- as.factor(mtcars$vs)
mtcars$am <- as.factor(mtcars$am)
par(mfrow=c(3,2))
par(mar=c(2.5, 5.5, 1.5, 1.5))
boxplot(mpg ~ am, data = mtcars, xlab = "AM (Transmission type)",
ylab = "MPG (Miles per galon)", main="Boxplot", xaxt="n", col=c("red","blue"))
axis(1, at=c(1,2), labels=c("automatic", "manual"))
par(mar=c(2.5, 5.5, 1.5, 1.5))
analysis <- aov(mpg ~ ., data = mtcars) #I run ANOVA
summary(analysis) #this returns a summary containing relevant statistics
plot(lm5)
summary(lm5)
getwd()
setwd("/Users/aliu/Documents/Data_Science_Coursera/RepData_PeerAssessment1")
getwd()
unzip(zipfile="activity.zip")
data <- read.csv("activity.csv")
## ------------------------------------------------------------------------
library(ggplot2)
total.steps <- tapply(data$steps, data$date, FUN=sum, na.rm=TRUE)
qplot(total.steps, binwidth=1000, xlab="total number of steps taken each day")
mean(total.steps, na.rm=TRUE)
median(total.steps, na.rm=TRUE)
## ------------------------------------------------------------------------
library(ggplot2)
averages <- aggregate(x=list(steps=data$steps), by=list(interval=data$interval),
FUN=mean, na.rm=TRUE)
ggplot(data=averages, aes(x=interval, y=steps)) +
geom_line() +
xlab("5-minute interval") +
ylab("average number of steps taken")
## ------------------------------------------------------------------------
averages[which.max(averages$steps),]
## ----how_many_missing----------------------------------------------------
missing <- is.na(data$steps)
# How many missing
table(missing)
## ------------------------------------------------------------------------
# Replace each missing value with the mean value of its 5-minute interval
fill.value <- function(steps, interval) {
filled <- NA
if (!is.na(steps))
filled <- c(steps)
else
filled <- (averages[averages$interval==interval, "steps"])
return(filled)
}
filled.data <- data
filled.data$steps <- mapply(fill.value, filled.data$steps, filled.data$interval)
## ------------------------------------------------------------------------
total.steps <- tapply(filled.data$steps, filled.data$date, FUN=sum)
qplot(total.steps, binwidth=1000, xlab="total number of steps taken each day")
mean(total.steps)
median(total.steps)
## ------------------------------------------------------------------------
weekday.or.weekend <- function(date) {
day <- weekdays(date)
if (day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday"))
return("weekday")
else if (day %in% c("Saturday", "Sunday"))
return("weekend")
else
stop("invalid date")
}
filled.data$date <- as.Date(filled.data$date)
filled.data$day <- sapply(filled.data$date, FUN=weekday.or.weekend)
## ------------------------------------------------------------------------
averages <- aggregate(steps ~ interval + day, data=filled.data, mean)
ggplot(averages, aes(interval, steps)) + geom_line() + facet_grid(day ~ .) +
xlab("5-minute interval") + ylab("Number of steps")
averages <- aggregate(x=list(steps=data$steps), by=list(interval=data$interval),
FUN=mean, na.rm=TRUE)
ggplot(data=averages, aes(x=interval, y=steps)) +
geom_line() +
xlab("5-minute interval") +
ylab("average number of steps taken")
## ------------------------------------------------------------------------
averages[which.max(averages$steps),]
## ----how_many_missing----------------------------------------------------
missing <- is.na(data$steps)
# How many missing
table(missing)
## ------------------------------------------------------------------------
# Replace each missing value with the mean value of its 5-minute interval
fill.value <- function(steps, interval) {
filled <- NA
if (!is.na(steps))
filled <- c(steps)
else
filled <- (averages[averages$interval==interval, "steps"])
total.steps <- tapply(data$steps, data$date, FUN=sum, na.rm=TRUE)
qplot(total.steps, binwidth=1000, xlab="total number of steps taken each day")
mean(total.steps, na.rm=TRUE)
median(total.steps, na.rm=TRUE)
## ------------------------------------------------------------------------
##library(ggplot2)
averages <- aggregate(x=list(steps=data$steps), by=list(interval=data$interval),
